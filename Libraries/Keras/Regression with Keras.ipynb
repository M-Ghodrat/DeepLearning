{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "minute-radar",
   "metadata": {},
   "source": [
    "# Regression with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-subscription",
   "metadata": {},
   "source": [
    "[link](https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-military",
   "metadata": {},
   "source": [
    "Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "interested-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-society",
   "metadata": {},
   "source": [
    "Define Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "prescribed-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2], [3,4], [5,6], [7,8], [9,10]])\n",
    "Y = np.array([[3], [4], [5], [6], [7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-august",
   "metadata": {},
   "source": [
    "Normalize Dataset, if not, the algorithm won't converge!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "academic-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()\n",
    "X = sc_X.fit_transform(X)\n",
    "\n",
    "# this is not required\n",
    "# sc_Y = StandardScaler()\n",
    "# Y = sc_Y.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-facial",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "conditional-sunrise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn_model():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(5, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(5, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    #Compile the model\n",
    "    model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-ceiling",
   "metadata": {},
   "source": [
    "## Method 1: By using `KerasRegressor`\n",
    "\n",
    "Using `KerasRegressor` is preferred when we want to evaluate the model via `cross_val_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "stuffed-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasRegressor(build_fn=fcn_model, epochs=300, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-carbon",
   "metadata": {},
   "source": [
    "1. To define the `Sequential` model, you could alternatively do:\n",
    "```python\n",
    "model = Sequential([\n",
    "    Dense(units=5, input_shape=(2,), activation='relu'),\n",
    "    Dense(units=5, activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "```\n",
    "\n",
    "2. Instead of defining function `fcn_model`, we can do:\n",
    "```python\n",
    "model=Sequential()\n",
    "model.add(Dense(5, input_dim=2, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "estimator = KerasRegressor(build_fn=lambda: model, epochs=300, batch_size=5, verbose=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-keyboard",
   "metadata": {},
   "source": [
    "## To get rid of warning for `tf.function` retracing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "julian-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-count",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "active-detector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-10.0504787  -39.40644809]\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=2)\n",
    "print(cross_val_score(estimator, X, Y, cv=kfold, scoring='neg_mean_squared_error'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-steel",
   "metadata": {},
   "source": [
    "**Note:** We can not use `model` instead of `estimator` in `cross_val_score` function since thre `model` is not an estimator. (All built-in estimators also have a **`set_params`** method, which sets data-independent parameters) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "variable-percentage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 300,\n",
       " 'batch_size': 5,\n",
       " 'verbose': 0,\n",
       " 'build_fn': <function __main__.fcn_model()>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "graduate-findings",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'get_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-26f8ffd4fa17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfcn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'get_params'"
     ]
    }
   ],
   "source": [
    "fcn_model().get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-dialogue",
   "metadata": {},
   "source": [
    "## To predict, we need to `.fit()` again:\n",
    "\n",
    "The fitting will be done inside the `cross_val_score` function, you don't need to worry about this beforehand.\n",
    "\n",
    "If, besides cross validation, you want to train a model, you can call `model.fit()` afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "british-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(X, Y, epochs=300, batch_size=5, verbose=0)\n",
    "prediction = estimator.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "numeric-conversation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]]\n",
      "[0.27051312 0.27051312 2.040389   3.3258193  4.631702  ]\n"
     ]
    }
   ],
   "source": [
    "print(Y)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-telephone",
   "metadata": {},
   "source": [
    "### Interesting - 2 observations:\n",
    "\n",
    "1. Using `lambda` inline function instead of `fnc_model` gives worse result!\n",
    "2. Running all cells in one cell gives better result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "retained-increase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00618585 -0.00685854]\n",
      "[[3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]]\n",
      "[3.0117946 3.9801488 5.0043645 6.0121584 6.9929504]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "import tensorflow as tf\n",
    "import numpy as ny\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = ny.array([[1,2], [3,4], [5,6], [7,8], [9,10]])\n",
    "Y = ny.array([[3], [4], [5], [6], [7]])\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "X = sc_X.fit_transform(X)\n",
    "\n",
    "def fnc_model():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(5, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(5, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #Compile the model\n",
    "    model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "    return model\n",
    "\n",
    "estimator = KerasRegressor(build_fn=lambda: model, epochs=300, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=2)\n",
    "print(cross_val_score(estimator, X, Y, cv=kfold, scoring='neg_mean_squared_error'))\n",
    "estimator.fit(X, Y, epochs=300, batch_size=5, verbose=0)\n",
    "prediction = estimator.predict(X)\n",
    "print(Y)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "careful-evanescence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-12.069893    -0.83921232]\n",
      "[[3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]]\n",
      "[3.4267864 3.533599  4.169761  5.865515  7.545754 ]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "import tensorflow as tf\n",
    "import numpy as ny\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = ny.array([[1,2], [3,4], [5,6], [7,8], [9,10]])\n",
    "Y = ny.array([[3], [4], [5], [6], [7]])\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "X = sc_X.fit_transform(X)\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(5, input_dim=2, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "#Compile the model\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "estimator = KerasRegressor(build_fn=lambda: model, epochs=300, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=2)\n",
    "print(cross_val_score(estimator, X, Y, cv=kfold, scoring='neg_mean_squared_error'))\n",
    "estimator.fit(X, Y, epochs=300, batch_size=5, verbose=0)\n",
    "prediction = estimator.predict(X)\n",
    "print(Y)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-garage",
   "metadata": {},
   "source": [
    "## Method 2: Without using `KerasRegressor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "still-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fcn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "functioning-marketplace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f87d06e4190>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size=5, epochs=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "charged-music",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(X) # may get warning when using prediction = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-smith",
   "metadata": {},
   "source": [
    "**Note:** We _may_ get warning when using `prediction = estimator.predict(X)`. So, we instead use `prediction = estimator.predict(X)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "superb-profit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]]\n",
      "tf.Tensor(\n",
      "[[2.988811]\n",
      " [4.029836]\n",
      " [4.923675]\n",
      " [5.787898]\n",
      " [7.291502]], shape=(5, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(Y)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-maximum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-myrtle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
